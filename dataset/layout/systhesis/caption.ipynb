{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"\n",
    "You are analyzing an application layout image where a specific UI element is highlighted. You'll receive both the full layout image and a cropped image of the highlighted element.\n",
    "And you will also receive a context image, which is the region of the full image that contains the bounding box of the element.\n",
    "\n",
    "As an experienced designer, provide a clear description of this element that would help developers, designers, and general users locate and understand it without relying on any highlighting.\n",
    "You CAN find the distinctive features of the element, describe the relationship between the element and other distinct elements, etc. Be creative, and find the most effective way to describe the element.\n",
    "\n",
    "Please, analyze the following aspects:\n",
    "\n",
    "### 1. Visual Description\n",
    "Describe the element's visual characteristics, including:\n",
    "- Geometric composition\n",
    "- Colors and styling\n",
    "- Visual context within the interface\n",
    "- Any notable design patterns or features\n",
    "\n",
    "### 2. Position Information\n",
    "Explain the element's location in relation to:\n",
    "- Overall screen placement (e.g., top-right corner)\n",
    "- Surrounding UI components\n",
    "- Parent containers or groups\n",
    "- Position within lists, tables, or other structured layouts\n",
    "\n",
    "### 3. Element Function\n",
    "Detail the element's purpose and interaction methods:\n",
    "- Primary functionality\n",
    "- Expected user interactions\n",
    "- Resulting actions or behaviors\n",
    "- Common use cases\n",
    "\n",
    "### 4. Element Type\n",
    "Identify the specific UI component type, such as:\n",
    "- Button\n",
    "- Text input\n",
    "- Dropdown menu\n",
    "- Checkbox\n",
    "- Toggle switch\n",
    "- Scrollbar\n",
    "- Other standard UI elements\n",
    "\n",
    "### 5. Element Completeness\n",
    "Assess whether the element is:\n",
    "- Fully visible\n",
    "- Partially truncated (specify which parts)\n",
    "- Part of a larger component\n",
    "\n",
    "Additional Context:\n",
    "You'll receive two pieces of metadata:\n",
    "\n",
    "1. Element Name: An identifier that may or may not be meaningful\n",
    "2. Element Hierarchy: A parent-child relationship list where:\n",
    "   - Format: [Root, Parent, Child]\n",
    "   - Root typically indicates the application type (e.g., Zoom, Notion)\n",
    "   - Some labels may be generic (e.g., Frame, Group) and can be ignored\n",
    "   \n",
    "Use the hierarchy information to enhance your analysis while keeping descriptions concise and focused.\n",
    "\n",
    "Important: \n",
    "**NEVER** reference any highlighting or bounded areas in your description.\n",
    "Make every sentence to the point and concise, don't use vague words like \"specific area\" and \"certain region\", etc.\n",
    "Again, the user should be able to find the element even without the bounding box, you need to find the distinctive features of the element, describe the relationship between the element and other distinct elements, etc.\n",
    "Grasp the info that you seen, if you know the title, say the title, if you know the user name, say the user name, if you find some distinctive text, say the text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "The bounded image, cropped image and context image are provided in the following prompt.\n",
    "The name of the element is:\n",
    "{element_name}\n",
    "The hierarchy of the elements is:\n",
    "{hierarchy}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import jsonlines\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "data_dir = \"/mnt/moonfs/dengjiaqi-m2/OSWorld-G/layout_crawling/systhesis/cropped_data_v4\"\n",
    "\n",
    "def sample_from_jsonl(file_path: str, n_samples: int, random_seed: int = 0) -> List[dict]:\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # Read all data from jsonl file\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        data = list(reader)\n",
    "    \n",
    "    # Sample n examples\n",
    "    sampled_data = random.sample(data, n_samples)\n",
    "    return sampled_data\n",
    "\n",
    "# Example usage\n",
    "n_samples = 200\n",
    "random_seed = 0\n",
    "#samples = sample_from_jsonl(os.path.join(data_dir, \"layout2k_filtered.jsonl\"), n_samples, random_seed)\n",
    "# read the samples from the jsonl file\n",
    "with jsonlines.open(os.path.join(data_dir, \"layout2k_filtered.jsonl\")) as reader:\n",
    "    samples = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_context_region(image, bbox, context_size=512):\n",
    "    \"\"\"\n",
    "    获取包含 bounding box 和周围区域的图片，尽量保持 bounding box 在中心\n",
    "    \n",
    "    Args:\n",
    "        image: 原始图片\n",
    "        bbox: [x1, y1, x2, y2] 格式的 bounding box\n",
    "        context_size: 目标上下文区域的大小\n",
    "    \n",
    "    Returns:\n",
    "        裁剪后的图片\n",
    "    \"\"\"\n",
    "    img_height, img_width = image.shape[:2]\n",
    "\n",
    "    x = bbox['x']\n",
    "    y = bbox['y']\n",
    "    w = bbox['width']\n",
    "    h = bbox['height']\n",
    "\n",
    "    x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "    \n",
    "    # 转换为 x1, y1, x2, y2 格式\n",
    "    x1, y1 = x, y\n",
    "    x2, y2 = x + w, y + h\n",
    "    \n",
    "    # 计算 bbox 的中心点\n",
    "    center_x = (x1 + x2) // 2\n",
    "    center_y = (y1 + y2) // 2\n",
    "\n",
    "    # 计算理想的裁剪区域（以 bbox 中心为中心的 context_size x context_size 区域）\n",
    "    half_size = context_size // 2\n",
    "    crop_x1 = center_x - half_size\n",
    "    crop_y1 = center_y - half_size\n",
    "    crop_x2 = center_x + half_size\n",
    "    crop_y2 = center_y + half_size\n",
    "    \n",
    "    # 处理边界情况\n",
    "    if crop_x1 < 0:\n",
    "        # 左边界超出，向右移动裁剪区域\n",
    "        shift = -crop_x1\n",
    "        crop_x1 = 0\n",
    "        crop_x2 = min(img_width, crop_x2 + shift)\n",
    "    elif crop_x2 > img_width:\n",
    "        # 右边界超出，向左移动裁剪区域\n",
    "        shift = crop_x2 - img_width\n",
    "        crop_x2 = img_width\n",
    "        crop_x1 = max(0, crop_x1 - shift)\n",
    "        \n",
    "    if crop_y1 < 0:\n",
    "        # 上边界超出，向下移动裁剪区域\n",
    "        shift = -crop_y1\n",
    "        crop_y1 = 0\n",
    "        crop_y2 = min(img_height, crop_y2 + shift)\n",
    "    elif crop_y2 > img_height:\n",
    "        # 下边界超出，向上移动裁剪区域\n",
    "        shift = crop_y2 - img_height\n",
    "        crop_y2 = img_height\n",
    "        crop_y1 = max(0, crop_y1 - shift)\n",
    "    \n",
    "    # 裁剪图片\n",
    "    return image[crop_y1:crop_y2, crop_x1:crop_x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "full_image_dir = \"/mnt/moonfs/dengjiaqi-m2/OSWorld-G/layout_crawling/systhesis/cropped_data_v4/vis_images\"\n",
    "cropped_image_dir = \"/mnt/moonfs/dengjiaqi-m2/OSWorld-G/layout_crawling/systhesis/cropped_data_v4/cropped_images\"\n",
    "\n",
    "def format_messages(sample: dict) -> List[dict]:\n",
    "    # get the image from the sample\n",
    "    # sample_id = sample[\"id\"]\n",
    "    # image_name = sample[\"image_name\"].split(\".\")[0]\n",
    "    # image_path = os.path.join(image_dir, f\"{image_name}_{sample_id}.png\")\n",
    "\n",
    "    processed_image_name = sample[\"processed_image_name\"]\n",
    "\n",
    "    full_image_path = os.path.join(full_image_dir, processed_image_name)\n",
    "    cropped_image_path = os.path.join(cropped_image_dir, processed_image_name)\n",
    "    \n",
    "    # get the context region    \n",
    "    full_image = cv2.imread(full_image_path)\n",
    "    context_image = get_context_region(full_image, sample[\"position\"])\n",
    "    \n",
    "    # 创建临时文件保存上下文图\n",
    "    os.makedirs(\"./tmp\", exist_ok=True)\n",
    "    context_image_path = os.path.join(\"./tmp\", f\"context_{processed_image_name}\")\n",
    "    cv2.imwrite(context_image_path, context_image)\n",
    "\n",
    "    def encode_image(image_path: str) -> str:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    full_image_data = encode_image(full_image_path)\n",
    "    cropped_image_data = encode_image(cropped_image_path)\n",
    "    context_image_data = encode_image(context_image_path)\n",
    "\n",
    "    os.remove(context_image_path)\n",
    "\n",
    "    hierarchy = sample[\"hierarchy\"]\n",
    "    # convert hierarchy to a string\n",
    "    hierarchy_str = \"\\n\".join([f\"{i}: {caption}\" for i, caption in enumerate(hierarchy)])\n",
    "\n",
    "    element_name = sample[\"name\"]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": user_prompt.format(hierarchy=hierarchy_str, element_name=element_name)},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{full_image_data}\", \"detail\": \"high\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{cropped_image_data}\", \"detail\": \"high\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{context_image_data}\", \"detail\": \"high\"}}\n",
    "        ]}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class Response(BaseModel):\n",
    "    visual_description: str\n",
    "    position_information: str\n",
    "    element_function: str\n",
    "    element_type: str\n",
    "    element_completeness: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def analyze_sample(sample: dict) -> Response:\n",
    "    messages = format_messages(sample)\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-2024-08-06\",\n",
    "            messages=messages,\n",
    "            response_format=Response,\n",
    "            temperature=0\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_sample(sample: dict) -> dict:\n",
    "\n",
    "    # sample_id = sample[\"id\"]\n",
    "    # image_name = sample[\"image_name\"].split(\".\")[0]\n",
    "    # image_name = f\"{image_name}_{sample_id}.png\"\n",
    "\n",
    "    processed_image_name = sample[\"processed_image_name\"]\n",
    "    original_image_name = sample[\"original_image_name\"]\n",
    "\n",
    "    result = {\n",
    "        \"id\": sample[\"id\"],\n",
    "        \"original_image_name\": original_image_name,\n",
    "        \"processed_image_name\": processed_image_name,\n",
    "        \"bounding_box\": sample[\"position\"],\n",
    "        \"visual_description\": None,\n",
    "        \"position_information\": None,\n",
    "        \"element_function\": None,\n",
    "        \"element_type\": None,\n",
    "        \"element_completeness\": None,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = analyze_sample(sample)\n",
    "        response = json.loads(response)\n",
    "        result[\"visual_description\"] = response[\"visual_description\"]\n",
    "        result[\"position_information\"] = response[\"position_information\"]\n",
    "        result[\"element_function\"] = response[\"element_function\"]\n",
    "        result[\"element_type\"] = response[\"element_type\"]\n",
    "        result[\"element_completeness\"] = response[\"element_completeness\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      " 53%|█████▎    | 58116/110602 [3:59:56<2:05:44,  6.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 91106/110602 [5:54:13<1:04:28,  5.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 104468/110602 [6:46:45<35:28,  2.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 107067/110602 [7:01:31<12:49,  4.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110602/110602 [7:18:26<00:00,  4.20it/s]  \n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    futures = [executor.submit(process_sample, sample) for sample in samples]\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        data.append(future.result())\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(os.path.join(data_dir, \"layout2k_caption_full.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "output_dir = \"/mnt/moonfs/dengjiaqi-m2/OSWorld-G/layout_crawling/systhesis/cropped_data_v4/vis_images_full\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# extract all the images from the samples\n",
    "for sample in samples:\n",
    "    # image_name = sample[\"image_name\"].split(\".\")[0]\n",
    "    # image_name = f\"{image_name}_{sample['id']}.png\"\n",
    "    # image_path = os.path.join(image_dir, image_name)\n",
    "    processed_image_name = sample[\"processed_image_name\"]\n",
    "    try:\n",
    "        shutil.copy(os.path.join(full_image_dir, processed_image_name), os.path.join(output_dir, processed_image_name))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
